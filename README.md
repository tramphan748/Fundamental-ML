# Mini-Project for Fundamentals of Machine Learning Course
![background](./materials/ai_wp.jpg)
This repository contains the code and data for a mini-project on facial expression recognition using machine learning algorithms.

## üìë Project Policy
- Team: group should consist of 3-4 students.

    |No.| Student Name    | Student ID |
    | --------| -------- | ------- |
    |1|Nguy·ªÖn Ho√†ng Y·∫øn Nhi|21110358|
    |2|V≈© Minh Nh∆∞|21110360|
    |3|Phan H·ªìng Tr√¢m|21110414|

- The submission deadline is strict: **11:59 PM** on **June 22nd, 2024**. Commits pushed after this deadline will not be considered.

## üì¶ Project Structure

The repository is organized into the following directories:

- **/data**: This directory contains the facial expression dataset. You'll need to download the dataset and place it here before running the notebooks. (Download link provided below)
- **/notebooks**: This directory contains the Jupyter notebook ```EDA.ipynb```. This notebook guides you through exploratory data analysis (EDA) and classification tasks.

## ‚öôÔ∏è Usage

This project is designed to be completed in the following steps:

1. **Fork the Project**: Click on the ```Fork``` button on the top right corner of this repository, this will create a copy of the repository in your own GitHub account. Complete the table at the top by entering your team member names.

2. **Download the Dataset**: Download the facial expression dataset from the following [link](https://mega.nz/file/foM2wDaa#GPGyspdUB2WV-fATL-ZvYj3i4FqgbVKyct413gxg3rE) and place it in the **/data** directory:

3. **Complete the Tasks**: Open the ```notebooks/EDA.ipynb``` notebook in your Jupyter Notebook environment. The notebook is designed to guide you through various tasks, including:
    
    1. Prerequisite
    2. Principle Component Analysis
       - [x] Question 1.
       - [x] Question 2.
    3. Image Classification
       - [x] MLP 
       - [x] Decision Tree
       - [x] kNN
       - [x] Naive Bayes
    4. Evaluating Classification Performance
    

    Make sure to run all the code cells in the ```EDA.ipynb``` notebook and ensure they produce output before committing and pushing your changes.

4. **Commit and Push Your Changes**: Once you've completed the tasks outlined in the notebook, commit your changes to your local repository and push them to your forked repository on GitHub.


Feel free to modify and extend the notebook to explore further aspects of the data and experiment with different algorithms. Good luck.

## üìã REPORT OF PROJECT
Trong project tr√™n, nh√≥m em s·ª≠ d·ª•ng 4 model ƒë·ªÉ hu·∫•n luy·ªán d·ªØ li·ªáu, g·ªìm: MLP Model, DecisionTree Classifier, KNeighbors Classifier v√† Naive Bayes model. D·ª±a v√†o Classification report v√† Confusion matrix, m√¥ h√¨nh KNeighbors Classifier l√† m√¥ h√¨nh t·ªët nh·∫•t v√† m√¥ h√¨nh t·ªá nh·∫•t l√† Naive Bayes model. K·∫øt lu·∫≠n d·ª±a v√†o vi·ªác accuracy score v√† main score l√† F1 c·ªßa model KNeighbors Classifier l√† cao nh·∫•t, ng∆∞·ª£c l·∫°i score c·ªßa Naive Bayes l√† th·∫•p nh·∫•t. 

|No.| Model    | Accuarary score of Original data|Accuarary score of transformed data|
| --------| -------- | ------- |------- |
|1|MLP model|0.35|0.36|
|2|Decision Tree model|0.30|0.24|
|3|kNN model|0.35|0.35|
|4|Naive Bayes model|0.20|0.33|

![bar chart](./materials/bar_chart.png)

#### Sau khi ch·ªçn ƒë∆∞·ª£c best model l√† kNN, ta fit l·∫°i model tr√™n t·∫≠p test c·ªßa original data v√† transformed data:
|No.| Score   | kNN model of Original data|kNN model of of transformed data|
| --------| -------- | ------- |------- |
|1|Accuaracy score|0.37|0.35|

#### ƒê·ªÉ nh·∫≠n d·∫°ng xem bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c n√†o l√† ch√≠nh x√°c, hay r·ªßi ro nh·∫•t, ta d·ª±a theo ƒëi·ªÉm f1, do ƒëi·ªÉm f1 cung c·∫•p m·ªôt th∆∞·ªõc ƒëo c√¢n b·∫±ng gi·ªØa ƒë·ªô ch√≠nh x√°c c·ªßa c√°c d·ª± ƒëo√°n d∆∞∆°ng t√≠nh v√† kh·∫£ nƒÉng ph√°t hi·ªán ra tr∆∞·ªùng h·ª£p d∆∞∆°ng t√≠nh, v√¨ v·∫≠y:
- The most accurate: c·∫£m x√∫c mang nh√£n s·ªë 3 "Happy".
- The most errors: c·∫£m x√∫c mang nh√£n s·ªë 0 "Angry".

## üí° INTERESTING FINDINGS
Trong qu√° tr√¨nh th·ª±c hi·ªán hu·∫•n luy·ªán model Decision tree, v√† khi th·ª±c hi·ªán fine tuning m√¥ h√¨nh c·ªßa d·ªØ li·ªáu g·ªëc, s·∫Ω xu·∫•t hi·ªán t√¨nh tr·∫°ng l√†m m·∫•t ƒëi ho√†n to√†n c√°c ƒë·∫∑c tr∆∞ng thu·ªôc nh√£n s·ªë 1, t·ª©c l√† c√°c ƒëi·ªÉm s·ªë nh∆∞ precision, recall v√† f-1 ƒë·ªÅu b·∫±ng 0.

**Nguy√™n nh√¢n:**

**1. Imbalanced data:**
Do trong t·∫≠p d·ªØ li·ªáu m·∫´u, c√°c d·ªØ li·ªáu mang nh√£n s·ªë 1 ch·ªâ c√≥ 63 m·∫´u trong khi c√°c d·ªØ li·ªáu thu·ªôc c√°c l·ªõp kh√°c c√≥ h∆°n 500 m·∫´u.

**2. Overfitting:**
Do m√¥ h√¨nh qu√° ph·ª©c t·∫°p v√† ch∆∞a t·ªëi ∆∞u ho√° ƒë√∫ng b·ªô tham s·ªë d·∫´n ƒë·∫øn c√¢y quy·∫øt ƒë·ªãnh ch∆∞a ƒë·ªß s√¢u ƒë·ªÉ ph√¢n t√°ch c√°c ƒë·∫∑c tr∆∞ng, n√™n n√≥ c√≥ th·ªÉ d·∫´n ƒë·∫øn vi·ªác h·ªçc c·ªßa m√¥ h√¨nh kh·ªõp v·ªõi t·∫≠p train m·ªôt c√°ch qu√° m·ª©c d·∫´n ƒë·∫øn vi·ªác kh√¥ng t·ªïng qu√°t ho√° t·ªët tr√™n t·∫≠p validation.

**Gi·∫£i ph√°p:** S·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t Pruning ƒë·ªÉ c·∫Øt t·ªâa b·ªõt m√¥ h√¨nh c√¢y nh·∫±m l√†m m√¥ h√¨nh tr·ªü n√™n c√¥ ƒë·∫∑c v√† t·ªëi ∆∞u ho√° h∆°n.
1. Pre-pruning
2. Post-pruning
